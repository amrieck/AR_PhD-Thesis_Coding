{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FRAP calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Script is trying to calculate FRAP data from given .csv files. It then export it as a summary csv containing all FRAPs of one experiment. For this to work filestructure needs to be like this\n",
    "\n",
    "Experiment ->\n",
    "\n",
    "    Condition -> \n",
    "    \n",
    "        FRAP-imamge1-bleach.csv\n",
    "        FRAP-image1-reference.csv\n",
    "        FRAP-image1-referencexor.csv\n",
    "        FRAP-image1-background\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import section\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath to this folder\n",
    "origin = os.getcwd()\n",
    "#print(origin)\n",
    "\n",
    "#get the experiment number\n",
    "Exp_no= os.path.basename(os.path.abspath(os.path.join(origin, os.pardir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function gets the subdirectory names and dreturns them\n",
    "def get_subdirnames (input):\n",
    "    \n",
    "    folders=[]\n",
    "    \n",
    "    for dirpath, dirnames, filenames in os.walk(input):\n",
    "        for folder in dirnames:\n",
    "            if folder ==\".ipynb_checkpoints\":\n",
    "                continue\n",
    "            folders.append(os.path.join(dirpath,folder))\n",
    "            \n",
    "    return folders\n",
    "\n",
    "#gets a list of all the .csv files in afolder\n",
    "def get_files(input):\n",
    "    filelist=[]\n",
    "    fileextension=\".csv\"\n",
    "    \n",
    "    for dirpath, dirnames, filenames in os.walk(input):\n",
    "        for files in filenames:\n",
    "            if files.endswith(fileextension):\n",
    "                filelist.append(os.path.join(input,files))\n",
    "    \n",
    "    return filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_basename(name):\n",
    "    \n",
    "    #get basename\n",
    "    basename=os.path.basename(name)\n",
    "    \n",
    "    #remove fileending\n",
    "    basename=basename[:-4]\n",
    "    #print(basename)\n",
    "    #creats list [FRAP no, measurmenttype (Backgroun, reference etc.)]\n",
    "    \n",
    "    element=basename.split(\"-\")\n",
    "    \n",
    "    return element\n",
    "\n",
    "def sortfiles(filelist):\n",
    "   \n",
    "    file_ends=[\"background.csv\",\"reference.csv\",\"xor.csv\",\"bleach.csv\"]\n",
    "    suffixdic={}\n",
    "    pathdic={}\n",
    "    firstrun=True\n",
    "    \n",
    "    for end in file_ends:\n",
    "        #print(end)\n",
    "        for path in filelist:\n",
    "            \n",
    "            if path.endswith(end):\n",
    "                name=split_basename(path)\n",
    "                #print(name)\n",
    "                suffixdic[name[0]]={name[1]:path}\n",
    "                #display(suffixdic)\n",
    "        \n",
    "        if firstrun==True:\n",
    "            pathdic=suffixdic\n",
    "            firstrun=False\n",
    "       \n",
    "        else:\n",
    "            pathdic={k:{**pathdic[k], **suffixdic[k]} for k in suffixdic}\n",
    "        suffixdic={}\n",
    "    #display(pathdic)\n",
    "    \n",
    "    return(pathdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['E200824_FRAP-2BP-BSA', 'E200824_FRAP-2BP-DMEM', 'E200824_FRAP-2BP-OA', 'E200824_FRAP-BSA', 'E200824_FRAP-DMEM', 'E200824_FRAP-DMSO-BSA', 'E200824_FRAP-DMSO-OA', 'E200824_FRAP-OA', 'E200824_FRAP-Palmo-BSA', 'E200824_FRAP-Palmo-DMEM', 'E200824_FRAP-Palmo-OA'])\n"
     ]
    }
   ],
   "source": [
    "sortedPaths={}\n",
    "subdirlist=get_subdirnames(origin)\n",
    "#print(\"subdirpaths:\\n\",subdirlist)\n",
    "\n",
    "for item in subdirlist:\n",
    "    condition=os.path.basename(item)\n",
    "    files=get_files(item)\n",
    "    sortedPaths[condition]=sortfiles(files)\n",
    "    \n",
    "print(sortedPaths.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Normalisations and FRAP curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Phair-normalisation from Ref, Refxor and bleach\n",
    "def calc_Phair(df):\n",
    "    \n",
    "    #Create a Backgroundsubstracted data of Reference, Reference of proximity of the bleach (xor)\n",
    "    #Put them in a new collumn (Always expand no data is overwritten)\n",
    "    df['Ref-Back']=df.reference-df.background #column no. 6\n",
    "    df['Refxor-Back']=df.referencexor-df.background #column no. 7\n",
    "    df['Bleach-Back']= df.bleach - df.background #column no. 8\n",
    "    \n",
    "    #Calculate the mean intensity of the five prebleach images(0:5) of the columns 6,7,8 \n",
    "    premean=df.iloc[0:5,5:9].mean()# ReferencePrebleach mean = premean[0], BleachPrebleach mean = premean[1]\n",
    "    #print(premean)\n",
    "   \n",
    "    MeanPreBleach=premean[2]\n",
    "    MeanPreReference=premean[0]\n",
    "    MeanPreReferencexor=premean[1]\n",
    "    \n",
    "    #Calculates Phair normalization ratio of pre-bleach mean Reference divided by each reference\n",
    "    #=> How much signal ist lost by just photobleaching\n",
    "    #Multiply that ratio with the Bleach values of all time points\n",
    "    # do that for both references\n",
    "    df['Phair'] = (MeanPreReference/df['Ref-Back'])*(df['Bleach-Back']/MeanPreBleach) #no9\n",
    "    df['Phairxor']= (MeanPreReferencexor/df['Refxor-Back'])*(df['Bleach-Back']/MeanPreBleach) #no10\n",
    "    \n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_0_1(df):\n",
    "    \n",
    "    # Make the minimum zero and the maximum 1 by substracting the min and divide by max\n",
    "    df['Featurescaled']= (df['Phair']-df['Phair'].min())/(df['Phair'].max()-df['Phair'].min()) #no11\n",
    "    df['Featurescaledxor']= (df['Phairxor']-df['Phairxor'].min())/(df['Phairxor'].max()-df['Phairxor'].min()) #no12\n",
    "    \n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the FRAP-Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is only for checking if all the curves were detected and created correctly. It is saved in the original files folder as pdf collecting all the figures of one FRAP-experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FRAP_plot(title, df, save):\n",
    "    \n",
    "    # Save is the folder in which the original files are to be found\n",
    "    \n",
    "    imsavepath= (save+\"_FRAP-curves.pdf\")\n",
    "    \n",
    "    #define y and x axis\n",
    "    \n",
    "    x= df.index\n",
    "    y1= df.bleach\n",
    "    y2= df.reference\n",
    "    y3= df.referencexor\n",
    "    y4= df.background\n",
    "    y5= df.Phair\n",
    "    y6= df.Featurescaled\n",
    "    y7= df.Phairxor\n",
    "    y8= df.Featurescaledxor\n",
    "    \n",
    "    with PdfPages(imsavepath) as export_pdf:\n",
    "        \n",
    "        #First image References bleach and Background\n",
    "        plt.scatter(x,y1, label ='Bleach')\n",
    "        plt.scatter(x,y2, label ='Reference')\n",
    "        plt.scatter(x,y3, label ='Reference-XOR')\n",
    "        plt.scatter(x,y4, label ='Background')\n",
    "    \n",
    "        plt.xlabel('time [sec]')\n",
    "        plt.ylabel('Intensity')\n",
    "    \n",
    "        plt.title(title+'FRAP-Curve')\n",
    "    \n",
    "        plt.legend()\n",
    "        #plt.show()\n",
    "        export_pdf.savefig()\n",
    "        plt.close()\n",
    "        \n",
    "        #Second image Phair Featurscaled with normal reference\n",
    "        plt.scatter(x,y5, label ='Phair')\n",
    "        plt.scatter(x,y6, label ='Featurescaled')    \n",
    "        plt.xlabel('time[sec]')\n",
    "        plt.ylabel('Relative intensity')\n",
    "        plt.title(title+'Normalized-Curve')\n",
    "    \n",
    "        plt.legend()\n",
    "        #plt.show()\n",
    "        export_pdf.savefig()\n",
    "        plt.close()\n",
    "        \n",
    "        #Third image Phair Featurescaled with xor derived reference\n",
    "        plt.scatter(x,y7, label ='Phair-XOR')\n",
    "        plt.scatter(x,y8, label ='Featurescaled-XOR')    \n",
    "        plt.xlabel('time[sec]')\n",
    "        plt.ylabel('Relative intensity')\n",
    "        plt.title(title+'Normalized-Curve')\n",
    "    \n",
    "        plt.legend()\n",
    "        #plt.show()\n",
    "        export_pdf.savefig()\n",
    "        plt.close()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_FRAP(dic, Fname):\n",
    "    \n",
    "    path_dic=dic[Fname]\n",
    "    fields={'X','Y'}\n",
    "    first_run=True\n",
    "        \n",
    "    for key in path_dic:\n",
    "        #print(key)\n",
    "        csv_path=path_dic[key]    \n",
    "           # print (csv_path)\n",
    "        \n",
    "        with open(csv_path) as file:\n",
    "            tempDF=pd.read_csv(file,skipinitialspace=True, usecols=fields, index_col=False)\n",
    "            \n",
    "        if first_run==True:\n",
    "            DF=tempDF\n",
    "            DF.columns=['time',key]\n",
    "            DF.set_index('time')\n",
    "            first_run=False\n",
    "                \n",
    "        else:\n",
    "            DF[key]=tempDF['Y']\n",
    "            DF.set_index('time')\n",
    "    DF=calc_Phair(DF)\n",
    "    DF=calc_0_1(DF)\n",
    "    #display(DF)\n",
    "    \n",
    "    spath= os.path.join(os.path.abspath(os.path.join(csv_path, os.pardir)), Fname)\n",
    "    #print(spath)\n",
    "    DF.to_csv(spath+\"_analysis.csv\")\n",
    "    FRAP_plot(Fname,DF, spath)\n",
    "    \n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary(PandaList, name):\n",
    "    \n",
    "    \n",
    "    SummaryDF={}\n",
    "    Summaryxor={}\n",
    "    \n",
    "    for key in PandaList:\n",
    "        \n",
    "        df=PandaList[key]\n",
    "        xor=PandaList[key]\n",
    "        SummaryDF[key]=df.iloc[5:,10].values\n",
    "        Summaryxor[key]=xor.iloc[5:,11].values\n",
    "  \n",
    "    time= df.time.values\n",
    "    time= time[5:]\n",
    "    startT=min(time)\n",
    "    time[:]= [t - startT for t in time]\n",
    "   \n",
    "    path=os.path.join(name+\"_summary.csv\")\n",
    "    xorpath=os.path.join(name+\"_xor_summary.csv\")\n",
    "    \n",
    "    #display(SummaryDF)\n",
    "    FinalDF=pd.DataFrame.from_dict(SummaryDF)\n",
    "    FinalDFxor=pd.DataFrame.from_dict(Summaryxor)\n",
    "    \n",
    "    #display(FinalDF)\n",
    "    \n",
    "    FinalDF.index=time\n",
    "    FinalDFxor.index=time\n",
    "    \n",
    "    FinalDF.to_csv(path)\n",
    "    FinalDFxor.to_csv(xorpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E200824_FRAP-2BP-BSA\n",
      "FRAP01Ch01\n",
      "FRAP02Ch01\n",
      "FRAP03Ch01\n",
      "FRAP04Ch01\n",
      "FRAP05Ch01\n",
      "FRAP06Ch01\n",
      "E200824_FRAP-2BP-DMEM\n",
      "FRAP01Ch01\n",
      "FRAP02Ch01\n",
      "FRAP03Ch01\n",
      "FRAP04Ch01\n",
      "FRAP05Ch01\n",
      "FRAP06Ch01\n",
      "E200824_FRAP-2BP-OA\n",
      "FRAP01Ch01\n",
      "FRAP02Ch01\n",
      "FRAP03Ch01\n",
      "FRAP04Ch01\n",
      "FRAP05Ch01\n",
      "FRAP06Ch01\n",
      "E200824_FRAP-BSA\n",
      "FRAP01Ch01\n",
      "FRAP02Ch01\n",
      "FRAP03Ch01\n",
      "FRAP04Ch01\n",
      "FRAP05Ch01\n",
      "FRAP06Ch01\n",
      "E200824_FRAP-DMEM\n",
      "FRAP01Ch01\n",
      "FRAP02Ch01\n",
      "FRAP03Ch01\n",
      "FRAP04Ch01\n",
      "FRAP05Ch01\n",
      "E200824_FRAP-DMSO-BSA\n",
      "FRAP01Ch01\n",
      "FRAP02Ch01\n",
      "FRAP03Ch01\n",
      "FRAP04Ch01\n",
      "FRAP05Ch01\n",
      "FRAP06Ch01\n",
      "E200824_FRAP-DMSO-OA\n",
      "FRAP01Ch01\n",
      "FRAP02Ch01\n",
      "FRAP03Ch01\n",
      "FRAP04Ch01\n",
      "FRAP05Ch01\n",
      "FRAP06Ch01\n",
      "E200824_FRAP-OA\n",
      "FRAP01Ch01\n",
      "FRAP02Ch01\n",
      "FRAP03Ch01\n",
      "FRAP04Ch01\n",
      "FRAP05Ch01\n",
      "FRAP06Ch01\n",
      "E200824_FRAP-Palmo-BSA\n",
      "FRAP01Ch01\n",
      "FRAP02Ch01\n",
      "FRAP03Ch01\n",
      "E200824_FRAP-Palmo-DMEM\n",
      "FRAP01Ch01\n",
      "FRAP02Ch01\n",
      "FRAP03Ch01\n",
      "E200824_FRAP-Palmo-OA\n",
      "FRAP01Ch01\n",
      "FRAP02Ch01\n",
      "FRAP03Ch01\n",
      "FRAP04Ch01\n",
      "FRAP05Ch01\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for condition in sortedPaths:\n",
    "    print(condition)\n",
    "    DFDic={}\n",
    "    for key in sortedPaths[condition]:\n",
    "        print(key)\n",
    "        DFDic[key]=(load_FRAP(sortedPaths[condition],key))\n",
    "    create_summary(DFDic, condition)\n",
    "    \n",
    "print(\"DONE\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
